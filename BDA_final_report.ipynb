{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Logistic Regression for a Finger Tapping Task</center></h1>\n",
    "<h3><center>Bayesian Data Analysis project</center></h3>\n",
    "\n",
    "<h4><center>Pola Elisabeth Schw√∂bel (190792), Jia Qian (183308)</center></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pystan\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import PSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "subtracted_means_train = np.load('data/fully_preprocessed/subtracted_mean_train.npy')\n",
    "subtracted_means_test = np.load('data/fully_preprocessed/subtracted_mean_test.npy')\n",
    "train_labels = np.load('data/aligned_labels_train.npy')\n",
    "test_labels = np.load('data/aligned_labels_test.npy')\n",
    "participant_labels_train = np.load('data/participants_labels_train.npy')\n",
    "participant_labels_test= np.load('data/participants_labels_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The task\n",
    "Subjects perform one out of two motor tasks (tap with their left finger or tap with their right finger) while their brain activity is recorded via functional magnetic resonance imaging (fMRI). We aim to build an algorithm that can distinguish between the two tasks, i.e. predict whether the subject was tapping left or right based on their brain activity. An example fMRI image can be seen below:\n",
    "\n",
    "![](report_images/example_slices.png)\n",
    "\n",
    " *Figure 1: Example brain scans. Three possible directions in which to extract brain slices are shown (coronal/saggital and axial view). For our task, we will be working on axial view slices (rightmost image).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data and Preprocessing\n",
    "\n",
    "\n",
    "We have fMRI brain scans from 29 subjects, these are all young, healthy adults. The data is 4 dimensional: Volumetric brain scans varying over time.\n",
    "Participants were scanned while performing a blockdesign\n",
    "motor task, where they were visually cued by a blinking\n",
    "light, indicating whether they should tap their fingers on their\n",
    "right (green light) or left hand (red light). In between the tapping tasks is a resting block. The sequence \"right-rest-left-rest\" is performed 10 times for each subject. Task blocks were 20 s in length,\n",
    "and rest blocks were 9.88 s (597.6 s total scan time). (See [1] for further details.)\n",
    "\n",
    "\n",
    "![](report_images/onset.png)\n",
    "   *Figure 2: Block design. The task onsets for left and right are marked by vertical lines. The dashed lines represent the expected brain activity we will be measuring.*\n",
    "\n",
    "As a preprocessing step, we select relevant slices by considering fixed time points at only one location in the brain. The time points can easily be selected given the task onsets above. For the spatial selection, however, we perform a preliminary analysis: We subtract the two expected brain activities from Figure 2 to form a \"regressor\". For a participant in the training set, we then look for voxels which show activation following that pattern. \n",
    "\n",
    "<img src=\"report_images/regressor.png\" width=\"600\">\n",
    "\n",
    "*Figure 3: \"Regressor\" - relevant signal we are looking for.\"*\n",
    "\n",
    "Figure 4 shows the results of this analysis. The voxels with large negative correlation to the signal (red) are active when the participants clap right. Voxels with large positive correlation to the signal (blue) are active when the participants clap left. \n",
    "\n",
    "<img src=\"report_images/relevant_slices.png\" width=\"1200\">\n",
    "\n",
    "\n",
    "   *Figure 4: Voxels exhibiting a strong signal following the block design stimuli.*\n",
    "\n",
    "This plot indicates that the strongest signal is exhibited around 43 in this participant. Since the images are all pre-aligned we can assume this is also the case for the rest of the participants and we thus choose to work on slice 43 throughout. Once the slices are selected, we downsample them by a factor 4 in x- and y-direction to the large computational costs of the STAN sampling. Additionally, we subtract the mean to enhance the differences between the conditions. After this preprocessing pipeline, we are left with 120x29 = 3480 images of shape 14x16 each.\n",
    "\n",
    "![](report_images/preprocessing.png)\n",
    "\n",
    "   *Figure 5: Preprocessed images. (Example image, mean image from the same participant and example image where mean image has been subtracted, all downsampled.)*\n",
    "   \n",
    "[1] *Rasmussen, P. M., Hansen, L. K., Madsen, K. H., Churchill, N. W., & Strother, S. C. (2012). Model sparsity and brain pattern interpretation of classification models in neuroimaging. Pattern Recognition, 45(6), 2085-2100.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models\n",
    "## 3.1 Pooled Model\n",
    "\n",
    "As discussed above, we aim to distinguish between two conditions: 'tap left' encoded  as 0, and 'tap right' which we encode as 1. For each image, are interested in $\\theta$, the probability for the label being 1. The label distribution is bernoulli with \n",
    "$$\n",
    "    p(y|\\theta) = \\theta^y (1-\\theta)^{1-y}. \n",
    "$$\n",
    "\n",
    "$\\theta$ is obtained from the images via logistic regression as follows: We model \n",
    "\n",
    "$$ z = x \\beta + \\alpha.$$\n",
    "\n",
    "We put a normal prior on the weights (both intercept $\\alpha$ and slope $\\beta$, $w = (\\alpha, \\beta)$), \n",
    "\n",
    "$$ p(w) = \\mathcal{N}(w|0, \\sigma^2 I), $$\n",
    "\n",
    "effectively regularizing the regression and forcing the weights close to zero. \n",
    "\n",
    "The regression output values z are then transferred into probabilities via the inverse logistic transformation\n",
    "\n",
    "$$ \\text{logit}^{-1}: IR \\rightarrow (0, 1),  \\ \\text{logit}^{-1}(z) = \\frac{e^z}{1+e^z},$$ \n",
    "yielding \n",
    "$$\\theta = \\text{logit}^{-1}(z).$$\n",
    "\n",
    "Below is the STAN code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = subtracted_means_train.shape[1]\n",
    "per_voxel_std = subtracted_means_train.std(axis=0).mean()\n",
    "pooled_data_dict = {'y': train_labels,\n",
    "               'x': subtracted_means_train,\n",
    "               'N': len(train_labels), \n",
    "               'K': K, \n",
    "               'prior_alpha_cov': per_voxel_std,\n",
    "               'prior_beta_cov': np.eye(K)*per_voxel_std, \n",
    "               'zero_vector': np.zeros(K)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_code = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;   // number of data items\n",
    "  int<lower=0> K;   // number of predictors\n",
    "  matrix[N, K] x;   // predictor matrix\n",
    "  matrix[K, K] prior_beta_cov; //covariance matrix for prior on weights\n",
    "  real<lower=0> prior_alpha_cov; // covariance for prior on intercept\n",
    "  vector[K] zero_vector; // will be zero vector\n",
    "  int y[N];  // labels\n",
    "}\n",
    "parameters {\n",
    "  real alpha;           // intercept\n",
    "  vector[K] beta;       // coefficients for predictors\n",
    "}\n",
    "transformed parameters {\n",
    "    vector[N] z;      // regression outcome vector (inverse logit)\n",
    "    z = x * beta + alpha; //linear predictor\n",
    "}\n",
    "model {\n",
    "  alpha ~ normal(0, prior_alpha_cov); // prior on the intercept\n",
    "  // beta ~ multi_normal(zero_vector, prior_beta_cov); // prior on the weights\n",
    "  beta ~ normal(0, prior_alpha_cov);\n",
    "  y ~ bernoulli_logit(z); \n",
    "}\n",
    "generated quantities {\n",
    "    vector[N] log_lik; //log likelihoods\n",
    "    for (i in 1:N)\n",
    "        log_lik[i] = bernoulli_logit_lpmf( y[i] | z[i]);\n",
    "}\"\"\"\n",
    "pooled_model = pystan.StanModel(model_code=pooled_code)\n",
    "pooled_fit = pooled_model.sampling(data=pooled_data_dict, iter=2000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_model_dict = pickle.load(open(\"models/subtracted_mean_pooled_FINAL.p\", 'rb'))\n",
    "pooled_fit = pooled_model_dict['fit']\n",
    "s = pooled_fit.summary()\n",
    "summary = pd.DataFrame(s['summary'], columns=s['summary_colnames'], index=s['summary_rownames'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1.1 Convergence Analysis and Model Interpretation__:\n",
    "\n",
    "We plot a histograms of the $\\widehat{R}$ to get an idea about the convergence of our model. The values all very close to 1 incidcating convergence. (left plot)\n",
    "\n",
    "As another sanity check (right plot), we plot the mean $\\beta$ for all draws and each pixel. This map of the regression slopes can be viewed as a feature map, indicating which part of the brain are relevant for the regression task. We see that the feature map relfects the expected activations from Figure 4 very well, indicating a meaningful model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].hist(summary.loc[:, 'Rhat'])\n",
    "ax[0].set_title('Histogram of $\\widehat{R}$')\n",
    "mean_beta  = pooled_fit['beta'].mean(axis=0)\n",
    "ax[1].imshow(mean_beta.reshape(14, 16));\n",
    "ax[1].set_title(r'Mean of draws for $\\beta$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1.2 Evaluation of model fit with PSIS-loo cross-validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_likelihoods = pooled_fit['log_lik']\n",
    "# cross validated fit\n",
    "loo, _, ks = PSIS.psisloo(log_likelihoods)\n",
    "# raw fit\n",
    "lppd = np.sum(np.log(np.exp(log_likelihoods).mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, 0.9993383660411598)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate loo-fit and raw fit\n",
    "loo, np.exp(lppd/3120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, we encounter numerical problems evaluating the model fit with the loo-cross validation scheme. To get an idea of the problem and the quality of the fit, we investigate the raw likelihoods instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.exp(log_likelihoods.flatten()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the likelihoods are very close to one, this indicates overfitting and is probably the reason for the numerical issues. We discuss this more in the conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1.3 Predictive Performance__\n",
    "\n",
    "We evaluate the predictive performance on unseen test data. For the pooled model, we have left out all samples from 3 participants. We now evaluate the perfomance on those. \n",
    "\n",
    "In order to do this, we extract all the sampled $\\alpha$ and $\\beta$ from the model. We then perform the regression as described above, mapping each new image $x_t$ to a probabilitiy via\n",
    "$$ z = x_t \\beta + \\alpha$$\n",
    "and\n",
    "$$\\theta = \\text{logit}^{-1}(z).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(images, beta, alpha):\n",
    "    nr_images = images.shape[0]\n",
    "    nr_samples = beta.shape[0]\n",
    "    predictions = np.empty((nr_samples, nr_images))\n",
    "    for i in range(nr_samples):\n",
    "        predictions[i, :] = alpha[i] + np.matmul(subtracted_means_test, beta[i, :])\n",
    "    return expit(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = make_predictions(subtracted_means_test, pooled_fit['beta'], pooled_fit['alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we obtain a distribution over $\\theta$ for each image $x_t$. We plot the distribution for the first test image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct label is: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_predictions[:, 0], range=[0, 1]);\n",
    "plt.xlabel(r'$\\theta$');\n",
    "print('The correct label is:', test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is very peaky around 0, which is indeed the true label. Our model makes the correct prediction, and does so with high confidence. To get an overall measure for predictive performance, we compute the mean $\\theta$ over all samples for each image. We then make a prediction by simple thresholding the mean $\\theta$ at 0.5.\n",
    "\n",
    "We thereby obtain an a posteriori point estimate that we can compare to the true label. Proceeding this way, we obtain an accuracy of 98.86 %, as can be seen in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy corresponding to the maximum a posterior estimates is: 0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "max_a_posteriori = test_predictions.mean(axis=0).round().astype(int)\n",
    "print('The test accuracy corresponding to the maximum a posterior estimates is:',\n",
    "      sum(max_a_posteriori==test_labels)/len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Hierarchical Model\n",
    "\n",
    "In the hierarchical model, every participant has their own model, parameterized by $\\alpha_p$ and $\\beta_p$, while from the same distribution as illustrated below.\n",
    "\n",
    "<img src=\"report_images/hierarchical.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "More specifically, we have $\\theta$ as the likelihood of \"1\" as in pooled model, the difference here is that assume every participant has his\\her own model. \n",
    "$$\n",
    "     p(y|\\theta) = \\theta^y (1-\\theta)^{1-y}. \n",
    "$$ \n",
    "$$\n",
    "z_{ip} = x_{i\\in p} \\beta_p + \\alpha_p.$$\n",
    "\n",
    "$\\beta$ is zero-mean multivariate normal distribution with different variances for different models. For one specific model p, its all dimensions have the identical variance $\\sigma_p$.\n",
    "$$\\beta_p \\sim N(0,\\sigma_p)  $$\n",
    "\n",
    "And $\\alpha_p$ is normal distribution as well, with zero mean and identical variance for all participants.\n",
    "$$ \\alpha_p \\sim N(0, \\eta)$$\n",
    "\n",
    "\n",
    "The regression output values $z_p$ are then transferred into probabilities via the inverse logistic transformation\n",
    "\n",
    "$$ \\text{logit}^{-1}: IR \\rightarrow (0, 1),  \\ \\text{logit}^{-1}(z_{ip}) = \\frac{e^{z_{ip}}}{1+e^{z_{ip}}},$$ \n",
    "yielding \n",
    "$$\\theta_i = \\text{logit}^{-1}(z_{ip}).$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Data processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig size (2900, 99)\n",
      "test size (580, 99)\n"
     ]
    }
   ],
   "source": [
    "train = np.load('new_data/aligned_train.npy')\n",
    "test = np.load('new_data/aligned_test.npy')\n",
    "train_labels = np.load('new_data/aligned_labels_train.npy')\n",
    "test_labels = np.load('new_data/aligned_labels_test.npy')\n",
    "participant_labels_train = np.load('new_data/participants_labels_train.npy')\n",
    "participant_labels_test= np.load('new_data/participants_labels_test.npy')\n",
    "N_tr = train.shape[0]\n",
    "N_te = test.shape[0]\n",
    "train_down = train[:,::6,::6].flatten().reshape(N_tr,-1)\n",
    "test_down = test[:,::6,::6].flatten().reshape(N_te,-1)\n",
    "train_down = (train_down-np.min(train_down))/(np.max(train_down)-np.min(train_down))\n",
    "test_down = (test_down-np.min(test_down))/(np.max(test_down)-np.min(test_down))\n",
    "subtracted_means_train = train_down\n",
    "subtracted_means_test = test_down\n",
    "\n",
    "participant_labels_test[participant_labels_test==0] = 26\n",
    "participant_labels_test[participant_labels_test==1] = 27\n",
    "participant_labels_test[participant_labels_test==2] = 28\n",
    "subtracted_means_data = np.vstack((subtracted_means_train,subtracted_means_test))\n",
    "y_labels = np.vstack((train_labels.reshape(-1,1),test_labels.reshape(-1,1)))\n",
    "participant_labels = np.vstack((participant_labels_train.reshape(-1,1),participant_labels_test.reshape(-1,1)))\n",
    "num_pix = train_down.shape[1]\n",
    "X_tr = np.zeros((100*29,num_pix),dtype=float)\n",
    "X_te = np.zeros((20*29,num_pix),dtype=float)\n",
    "Y_tr = np.zeros((100*29,1),dtype=int)\n",
    "Y_te = np.zeros((20*29,1),dtype=int)\n",
    "participant_labels_tr = np.zeros((100*29,1),dtype=int)\n",
    "participant_labels_te = np.zeros((20*29,1),dtype=int)\n",
    "for i in range(29):\n",
    "    X_tr[i*100:(i+1)*100,:] = subtracted_means_data[np.where(participant_labels==i)[0][:100],:]\n",
    "    X_te[i*20:(i+1)*20,:] = subtracted_means_data[np.where(participant_labels==i)[0][100:120],:]\n",
    "    Y_tr[i*100:(i+1)*100] = y_labels[np.where(participant_labels==i)[0][:100]]\n",
    "    Y_te[i*20:(i+1)*20] = y_labels[np.where(participant_labels==i)[0][100:120]]\n",
    "    participant_labels_tr[i*100:(i+1)*100] = participant_labels[np.where(participant_labels==i)[0][:100]]\n",
    "    participant_labels_te[i*20:(i+1)*20] = participant_labels[np.where(participant_labels==i)[0][100:120]]\n",
    "print(\"trainig size\", X_tr.shape )\n",
    "print(\"test size\", X_te.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = X_tr.shape[1]\n",
    "hierarchical_data_dict = {'y': Y_tr.reshape(len(Y_tr)),\n",
    "               'x': X_tr,\n",
    "               'N': len(Y_tr), \n",
    "               'K': K , \n",
    "               'G': 29,\n",
    "               'g': participant_labels_tr.reshape(len(Y_tr))+1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_code = \"\"\"\n",
    "data {\n",
    "    int<lower=0> N;   // number of data items\n",
    "    int<lower=0> K;   // number of predictors\n",
    "    int<lower=0> G; // ADDED: number of groups \n",
    "    int<lower=1,upper=K> g[N]; // ADDED: group indicator \n",
    "    matrix[N, K] x;   // predictor matrix\n",
    "    int y[N];  // labels\n",
    "}\n",
    "parameters {\n",
    "  real alpha[G];           // group intercepts\n",
    "  matrix[G, K] beta;       // group coefficients for predictors\n",
    "  real<lower=0> prior_alpha_cov; // hyperprior:  covariance for prior on intercept\n",
    "  real<lower=0> prior_beta_cov[G]; //hyperprior: covariance matrix for prior on weights\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "    vector[N] z;      // regression outcome vector (inverse logit)\n",
    "    for (i in 1:N) {\n",
    "        z[i] = x[i] * beta[g[i]]'  + alpha[g[i]]; }\n",
    "}\n",
    "\n",
    "model {\n",
    "  alpha ~ normal(0, prior_alpha_cov); // prior on the intercept\n",
    "  for (i in 1:G) {\n",
    "      beta[i] ~ normal(0, prior_beta_cov[i]); } // prior on the weights\n",
    "  y ~ bernoulli_logit(z); \n",
    "}\"\"\"\n",
    "hierarchical_model = pystan.StanModel(model_code=hierarchical_code)\n",
    "hierarchical_fit = hierarchical_model.sampling(data=hierarchical_data_dict, iter=2000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    }
   ],
   "source": [
    "model_dict = pickle.load(open(\"model/model_fit_low_resolution_shuffle.pkl\", 'rb'))\n",
    "hierarchical_fit = model_dict['fit']\n",
    "mean_beta  = hierarchical_fit['beta'].mean(axis=0)\n",
    "alpha_mean = hierarchical_fit['alpha'].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Predictive performance\n",
    "\n",
    "Every participant has 120 images, we split it into training(100) and test(20) datasets.\n",
    "\n",
    "The predictive distribution:\n",
    "\n",
    "$p(y_*|D,x_*) = \\int p(y_*| \\rho,x_*)p(\\rho|D)d\\rho \\approx \\frac{1}{T} \\sum_{t=1}^T p(y_*|\\rho_t,x_*), \\rho_t \\sim p(\\rho|D) $\n",
    "\n",
    "Where D is the dataset, $\\rho$ represents the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_ave(images, beta, alpha):\n",
    "    nr_images = images.shape[0]\n",
    "    nr_samples = beta.shape[0]\n",
    "    predictions = np.empty((nr_images,nr_samples))\n",
    "    for j in range(29):\n",
    "        sub_test = images[j*20:(j+1)*20]\n",
    "        predictions[j*20:(j+1)*20,:] = np.matmul(sub_test,beta[:,j, :].T)+ alpha[:,j]\n",
    "    return expit(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP accuracy is  0.9982758620689656\n",
      "mean accuracy is  0.9982758620689656\n"
     ]
    }
   ],
   "source": [
    "test_predictions = make_predictions(X_te,mean_beta,alpha_mean)\n",
    "acc = np.sum(test_predictions.reshape(-1,1).round()==Y_te)/test_predictions.shape[0]\n",
    "print('MAP accuracy is ',acc)\n",
    "test_predictions_ = make_predictions_ave(X_te, hierarchical_fit['beta'], hierarchical_fit['alpha'])\n",
    "acc_ave = np.sum(np.mean(test_predictions_,axis=1).reshape(-1,1).round()==Y_te)/test_predictions_.shape[0]\n",
    "print('mean accuracy is ',acc_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effective number of parameters is  1242.2669961525967\n"
     ]
    }
   ],
   "source": [
    "from psis import psisloo\n",
    "log_likelihoods = hierarchical_fit['log_lik']\n",
    "loo, _, ks = psisloo(log_likelihoods)\n",
    "P_eff=np.sum(np.log(np.exp(log_likelihoods).mean(axis=0)))-loo\n",
    "print(\"effective number of parameters is \",P_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'k values')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.bar([1,2],[np.sum(ks<=0.7),np.sum(ks>0.7)])\n",
    "plt.xticks(np.arange(1,3),('<=0.7','>0.7'))\n",
    "plt.xlabel('k values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Convolutional Neural Network \n",
    "We compare the predictive performance of the statistical models to the one of a simple convolutional neural network. Out architecture has two convolutional layers each followed by a pooling layer, and a fully connected network with one hidden layer as defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CNN\n",
    "class CNN_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=30,kernel_size=4,padding=0,stride=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,padding=0,stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=30,out_channels=15,kernel_size=4,padding=0,stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,padding=0,stride=1)\n",
    "        self.num_fea = 15*20*25#20*20,26*26\n",
    "        self.fc1 = nn.Sequential(nn.Linear(in_features=self.num_fea,out_features=128,bias=True),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(in_features=128,out_features=2,bias=False))\n",
    "    def forward(self, x):\n",
    "        conv_x = self.conv1(x)\n",
    "        activated_x = F.relu(conv_x)\n",
    "        pooled_x = self.pool1(activated_x)\n",
    "        conv_x = self.conv2(pooled_x)\n",
    "        activated_x = F.relu(conv_x)\n",
    "        pooled_x = self.pool2(activated_x)\n",
    "        x1 = pooled_x.view(-1,self.num_fea)\n",
    "        x = self.fc1(x1)\n",
    "        return F.softmax(x, dim=1), conv_x, activated_x, pooled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the sake of demo, we load the trained model directly\n",
    "cnn = CNN_net()\n",
    "cnn.load_state_dict(torch.load('model/cnn'))\n",
    "out,conv_x, activated_x, pooled_x = cnn(torch.from_numpy(test_X))\n",
    "test_pred = torch.max(out, 1)[1].data.numpy()\n",
    "acc = np.sum(test_pred==test_label)/N_te\n",
    "print('test accuracy: ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN_net()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the learning curve of test data set, the test accuracy stablized around 0.8 after 150 epochs.\n",
    "\n",
    "<img src=\"FromJia/test_acc_150lp_fin.png\" style=\"width: 600px;\"/> \n",
    "\n",
    "We also plot the features from convolutional and pooled layers.\n",
    "\n",
    "<img src=\"FromJia/conv_layer.png\" style=\"width: 1000px;\"/>\n",
    "\n",
    "Visualization of convolutional layer\n",
    "\n",
    "<img src=\"FromJia/pool_layer.png\" style=\"width: 1000px;\"/> \n",
    "Visualization of pooled layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion\n",
    "\n",
    "Both the pooled and the hierarchical model reasonably fit the data.\n",
    "In the prediction task, both the pooled model and the hierarchical model have a good predictice accuracy (98.61% and 99.8% accuracy, respectively). Due to the different train-test-splits, however, the predictive performance isn't strictly comparable. \n",
    "The neural network performs less well.\n",
    "\n",
    "The models both solve the task to a satisfactory degree, but especially the pooled model seems to exhibit overfitting (likelihoods close to 1), which causes the PSIS-loo cross validation to break down due to numerical reasons. This might be due to the large number of parameters in the regression where we could regularize the model more by forcing the weights closer to zero or by explicitly enforcing sparsity (weights outside the brain should be zero). An alternative approach could be to pre-extract smaller feature vectors, for example with classic feature extraction or machine learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
